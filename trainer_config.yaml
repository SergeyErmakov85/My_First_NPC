MyAgent:
  trainer: ppo
  batch_size: 128
  beta: 0.001
  epsilon: 0.2
  lambd: 0.95
  learning_rate: 0.0003
  max_steps: 500000
  normalize: true
  num_epoch: 5
  time_horizon: 128
  reward_signals:
    extrinsic:
      strength: 1.0
      gamma: 0.99
  network_settings:
    normalize: true
    hidden_units: 128
    num_layers: 2