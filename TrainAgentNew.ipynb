{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaebdea",
   "metadata": {},
   "source": [
    "# Обучение агента в Unity ML-Agents с экспортом ONNX\n",
    "\n",
    "Этот ноутбук обучает агента из Unity-среды (`MyAgent?team=0`) с 6 наблюдениями, 2 непрерывными действиями и 1 дискретным действием. Используем PPO из `stable-baselines3` и экспортируем модель в ONNX для Unity.\n",
    "\n",
    "## Зависимости\n",
    "- Установите библиотеки:\n",
    "  ```bash\n",
    "  pip install mlagents==0.30.0 stable-baselines3==2.0.0 gymnasium==0.28.1 torch==2.0.1 onnx numpy psutil\n",
    "  ```\n",
    "- Убедитесь, что путь к `UnityEnvironment.exe` правильный.\n",
    "- Среда Unity должна быть собрана с `Behavior Name: MyAgent?team=0`.\n",
    "- Python 3.8, совместимый с `mlagents==0.30.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3191270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlagents==0.30.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (0.30.0)\n",
      "Requirement already satisfied: stable-baselines3==2.0.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: onnx in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (1.21.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: grpcio>=1.11.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (1.70.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (3.11.0)\n",
      "Requirement already satisfied: mlagents-envs==0.30.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (0.30.0)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (10.4.0)\n",
      "Requirement already satisfied: protobuf>=3.6 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (3.20.3)\n",
      "Requirement already satisfied: pyyaml>=3.1.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (6.0.2)\n",
      "Requirement already satisfied: tensorboard>=1.15 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (2.14.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (24.2.0)\n",
      "Requirement already satisfied: pypiwin32==223 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (223)\n",
      "Requirement already satisfied: cattrs<1.7,>=1.1.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents==0.30.0) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from stable-baselines3==2.0.0) (3.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from stable-baselines3==2.0.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from stable-baselines3==2.0.0) (3.7.5)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from gymnasium==0.28.1) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from gymnasium==0.28.1) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from gymnasium==0.28.1) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from gymnasium==0.28.1) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from torch==2.0.1) (3.1.4)\n",
      "Requirement already satisfied: gym>=0.21.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents-envs==0.30.0->mlagents==0.30.0) (0.26.2)\n",
      "Requirement already satisfied: pettingzoo==1.15.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from mlagents-envs==0.30.0->mlagents==0.30.0) (1.15.0)\n",
      "Requirement already satisfied: pywin32>=223 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from pypiwin32==223->mlagents==0.30.0) (306)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium==0.28.1) (3.21.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (2.3.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (3.0.6)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from tensorboard>=1.15->mlagents==0.30.0) (0.44.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from pandas->stable-baselines3==2.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from pandas->stable-baselines3==2.0.0) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.30.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.30.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.30.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->mlagents==0.30.0) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from gym>=0.21.0->mlagents-envs==0.30.0->mlagents==0.30.0) (0.0.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->mlagents==0.30.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->mlagents==0.30.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->mlagents==0.30.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->mlagents==0.30.0) (2024.8.30)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.30.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\.conda\\envs\\ml_agents\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->mlagents==0.30.0) (3.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlagents==0.30.0 stable-baselines3==2.0.0 gymnasium==0.28.1 torch==2.0.1 onnx numpy psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef8b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior Name: MyAgent?team=0\n",
      "Observation size: 6\n",
      "Continuous action size: 2\n",
      "Discrete action branches: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Импорт библиотек\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# Функция закрытия среды\n",
    "def close_unity_env(env):\n",
    "    try:\n",
    "        if env is not None:\n",
    "            env.close()\n",
    "            print('Среда Unity успешно закрыта.')\n",
    "        else:\n",
    "            print('Среда не инициализирована.')\n",
    "    except Exception as e:\n",
    "        print(f'Ошибка при закрытии среды: {e}')\n",
    "    finally:\n",
    "        import psutil\n",
    "        for proc in psutil.process_iter(['name']):\n",
    "            if proc.info['name'].lower() == 'unityenvironment.exe':\n",
    "                proc.kill()\n",
    "                print(f'Процесс UnityEnvironment.exe (PID: {proc.pid}) принудительно завершён.')\n",
    "            if 'unity' in proc.info['name'].lower():\n",
    "                proc.kill()\n",
    "                print(f\"Процесс {proc.info['name']} (PID: {proc.pid}) принудительно завершён.\")\n",
    "\n",
    "# Путь к среде Unity\n",
    "env_path = os.path.join(os.getcwd(), r'N:\\MyRL\\My_First_NPC\\MyfirstMPC\\UnityEnvironment.exe')\n",
    "\n",
    "# Настройка канала для ускорения симуляции\n",
    "engine_channel = EngineConfigurationChannel()\n",
    "engine_channel.set_configuration_parameters(time_scale=50.0, quality_level=0)\n",
    "\n",
    "# Инициализация среды\n",
    "try:\n",
    "    env = UnityEnvironment(file_name=env_path, worker_id=1, base_port=6000, side_channels=[engine_channel], timeout_wait=60)\n",
    "    env.reset()\n",
    "except Exception as e:\n",
    "    print(f'Ошибка инициализации среды: {e}')\n",
    "    close_unity_env(None)\n",
    "    raise\n",
    "\n",
    "# Получение имени поведения\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "print(f'Behavior Name: {behavior_name}')\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "# Проверка спецификации\n",
    "print(f'Observation size: {spec.observation_specs[0].shape[0]}')\n",
    "print(f'Continuous action size: {spec.action_spec.continuous_size}')\n",
    "print(f'Discrete action branches: {spec.action_spec.discrete_branches}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ed64f",
   "metadata": {},
   "source": [
    "## Создание кастомной нейросети\n",
    "\n",
    "Нейросеть для 6 наблюдений, 2 непрерывных и 1 дискретного действия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3c7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomActorCriticNet(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=128):\n",
    "        super(CustomActorCriticNet, self).__init__(observation_space, features_dim)\n",
    "        self.fc1 = nn.Linear(observation_space.shape[0], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, features_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomActorCriticNet,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    "    net_arch=[dict(pi=[64, 32], vf=[64, 32])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486f582",
   "metadata": {},
   "source": [
    "## Обёртка среды для Gymnasium\n",
    "\n",
    "Используем `Box` для непрерывных действий и обрабатываем дискретные внутри `step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568268c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnityGymWrapper(gym.Env):\n",
    "    def __init__(self, unity_env, behavior_name, spec):\n",
    "        super(UnityGymWrapper, self).__init__()\n",
    "        self.env = unity_env\n",
    "        self.behavior_name = behavior_name\n",
    "        self.spec = spec\n",
    "\n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(spec.observation_specs[0].shape[0],), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Action space: only continuous actions (2) in Box\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0, high=1.0, shape=(spec.action_spec.continuous_size,), dtype=np.float32\n",
    "        )\n",
    "        # Discrete action will be handled manually\n",
    "        self.discrete_branches = spec.action_spec.discrete_branches\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.env.reset()\n",
    "        decision_steps, _ = self.env.get_steps(self.behavior_name)\n",
    "        obs = decision_steps.obs[0][0]\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        # Ensure action is 2D: (num_agents, action_size)\n",
    "        continuous_action = np.asarray(action, dtype=np.float32).reshape(1, -1)\n",
    "        # Discrete action: threshold based on first continuous action\n",
    "        discrete_action = np.array([[1 if action[0] > 0 else 0]], dtype=np.int32)  # shape (1, num_discrete_branches)\n",
    "\n",
    "        action_tuple = ActionTuple()\n",
    "        action_tuple.add_continuous(continuous_action)\n",
    "        action_tuple.add_discrete(discrete_action)\n",
    "\n",
    "        self.env.set_actions(self.behavior_name, action_tuple)\n",
    "        self.env.step()\n",
    "\n",
    "        decision_steps, terminal_steps = self.env.get_steps(self.behavior_name)\n",
    "        if len(terminal_steps) > 0:\n",
    "            done = True\n",
    "            reward = float(terminal_steps.reward[0])\n",
    "            obs = terminal_steps.obs[0][0]\n",
    "        else:\n",
    "            done = False\n",
    "            reward = float(decision_steps.reward[0])\n",
    "            obs = decision_steps.obs[0][0]\n",
    "        info = {}\n",
    "        truncated = False\n",
    "\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def close(self):\n",
    "        close_unity_env(self.env)\n",
    "\n",
    "gym_env = UnityGymWrapper(env, behavior_name, spec)\n",
    "check_env(gym_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a14517",
   "metadata": {},
   "source": [
    "## Обучение модели\n",
    "\n",
    "Используем PPO для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8cf7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\ML_Agents\\lib\\site-packages\\stable_baselines3\\common\\policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.2     |\n",
      "|    ep_rew_mean     | -0.552   |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "Среда Unity успешно закрыта.\n",
      "Процесс Unity Hub.exe (PID: 107332) принудительно завершён.\n",
      "Процесс Unity.exe (PID: 196792) принудительно завершён.\n",
      "Процесс Unity Hub.exe (PID: 222720) принудительно завершён.\n",
      "Процесс Unity Hub.exe (PID: 223204) принудительно завершён.\n",
      "Процесс UnityCrashHandler64.exe (PID: 223496) принудительно завершён.\n",
      "Процесс UnityAutoQuitter.exe (PID: 228864) принудительно завершён.\n",
      "Процесс Unity.exe (PID: 230528) принудительно завершён.\n",
      "Процесс Unity.Licensing.Client.exe (PID: 230580) принудительно завершён.\n",
      "Процесс Unity.exe (PID: 231752) принудительно завершён.\n",
      "Процесс Unity.ILPP.Runner.exe (PID: 231912) принудительно завершён.\n",
      "Процесс UnityCrashHandler64.exe (PID: 231924) принудительно завершён.\n",
      "Процесс UnityAutoQuitter.exe (PID: 232112) принудительно завершён.\n",
      "Процесс UnityPackageManager.exe (PID: 232140) принудительно завершён.\n",
      "Процесс UnityShaderCompiler.exe (PID: 233004) принудительно завершён.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = PPO(\n",
    "        'MlpPolicy',\n",
    "        gym_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.01,\n",
    "        verbose=1\n",
    "    )\n",
    "    model.learn(total_timesteps=10)\n",
    "    model.save('ppo_myagent')\n",
    "except Exception as e:\n",
    "    print(f'Ошибка обучения: {e}')\n",
    "finally:\n",
    "    close_unity_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75070044",
   "metadata": {},
   "source": [
    "## Экспорт модели в ONNX\n",
    "\n",
    "Экспортируем модель в ONNX для Unity Barracuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f5c21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Модель успешно сохранена: trained_myagent.onnx\n",
      "Файл существует: True\n",
      "Ошибка при закрытии среды: No Unity environment is loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "\n",
    "# Кастомная обёртка для экспорта в ONNX с поддержкой Sentis\n",
    "class WrapperNet(torch.nn.Module):\n",
    "    def __init__(self, policy, continuous_action_size):\n",
    "        \"\"\"\n",
    "        Оборачивает политику PPO, добавляя тензоры для Unity ML-Agents Sentis.\n",
    "        :param policy: Политика PPO из stable-baselines3.\n",
    "        :param continuous_action_size: Размер непрерывных действий (2 для MyAgent).\n",
    "        \"\"\"\n",
    "        super(WrapperNet, self).__init__()\n",
    "        self.policy = policy\n",
    "\n",
    "        # version_number: MLAgents2_0 = 3\n",
    "        version_number = torch.tensor([3], dtype=torch.float32)\n",
    "        self.version_number = Parameter(version_number, requires_grad=False)\n",
    "\n",
    "        # memory_size: 0, так как нет RNN\n",
    "        memory_size = torch.tensor([0], dtype=torch.float32)\n",
    "        self.memory_size = Parameter(memory_size, requires_grad=False)\n",
    "\n",
    "        # continuous_action_output_shape: [2] для 2 непрерывных действий\n",
    "        continuous_shape = torch.tensor([continuous_action_size], dtype=torch.float32)\n",
    "        self.continuous_shape = Parameter(continuous_shape, requires_grad=False)\n",
    "\n",
    "    def forward(self, obs, mask):\n",
    "        \"\"\"\n",
    "        Прямой проход: вычисляет непрерывные действия и возвращает дополнительные тензоры.\n",
    "        :param obs: Наблюдения [batch_size, 6].\n",
    "        :param mask: Фиктивный вход для action_masks [batch_size, 2].\n",
    "        :return: continuous_actions, continuous_shape, version_number, memory_size.\n",
    "        \"\"\"\n",
    "        # Получаем непрерывные действия из политики\n",
    "        continuous_actions = self.policy(obs, deterministic=True)[0]\n",
    "        # Умножаем на mask (фиктивно, так как маски не используются)\n",
    "        continuous_actions = torch.mul(continuous_actions, mask)\n",
    "        return continuous_actions, self.continuous_shape, self.version_number, self.memory_size\n",
    "\n",
    "try:\n",
    "    # Переводим политику на CPU\n",
    "    policy = model.policy.to('cpu')\n",
    "    continuous_action_size = spec.action_spec.continuous_size  # 2 для MyAgent\n",
    "    wrapper_net = WrapperNet(policy, continuous_action_size)\n",
    "    \n",
    "    # Пример входных тензоров\n",
    "    dummy_input = torch.randn(1, spec.observation_specs[0].shape[0])  # [1, 6]\n",
    "    dummy_mask = torch.ones(1, continuous_action_size)  # [1, 2], фиктивная маска\n",
    "    \n",
    "    # Экспорт в ONNX\n",
    "    torch.onnx.export(\n",
    "        wrapper_net,\n",
    "        (dummy_input, dummy_mask),\n",
    "        'trained_myagent.onnx',\n",
    "        input_names=['obs_0', 'action_masks'],\n",
    "        output_names=['continuous_actions', 'continuous_action_output_shape', 'version_number', 'memory_size'],\n",
    "        dynamic_axes={\n",
    "            'obs_0': {0: 'batch'},\n",
    "            'action_masks': {0: 'batch'},\n",
    "            'continuous_actions': {0: 'batch'},\n",
    "            'continuous_action_output_shape': {0: 'batch'},\n",
    "            'version_number': {0: 'batch'},\n",
    "            'memory_size': {0: 'batch'}\n",
    "        },\n",
    "        opset_version=9,  # Пробуем opset 9 для Unity ML-Agents 2.0.1\n",
    "        verbose=False\n",
    "    )\n",
    "    print('Модель успешно сохранена: trained_myagent.onnx')\n",
    "    print('Файл существует:', os.path.exists('trained_myagent.onnx'))\n",
    "except Exception as e:\n",
    "    print(f'Ошибка экспорта ONNX: {e}')\n",
    "    print('Попробуйте opset_version=11 или проверьте версию Unity Sentis.')\n",
    "finally:\n",
    "    close_unity_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели\n",
    "\n",
    "Проверяем, как работает обученная модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    obs, _ = gym_env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = gym_env.step(action)\n",
    "        if done or truncated:\n",
    "            print('Эпизод завершён')\n",
    "            obs, _ = gym_env.reset()\n",
    "except Exception as e:\n",
    "    print(f'Ошибка тестирования: {e}')\n",
    "finally:\n",
    "    close_unity_env(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
